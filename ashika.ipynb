{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashikagade333/Ashikagade_INFO5371_Fall2023/blob/main/ashika.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db6cSXB6iQgj"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy0CZ7dqiQgp"
      },
      "outputs": [],
      "source": [
        "One interesting text classification task is sentiment analysis, where the goal is to determine the sentiment or emotion expressed in a given text, such as a product review, social media post, or customer feedback. Sentiment analysis can be useful for businesses to understand customer opinions, gauge product satisfaction, and make informed decisions based on public sentiment. Here are five types of features that could be valuable for building a sentiment analysis machine learning model:\n",
        "Bag of Words (BoW) Features:\n",
        "\n",
        "Word Frequency: Count the frequency of each word in the text. Positive and negative sentiment words can be given different weights to capture sentiment polarity.\n",
        "N-grams: Include bi-grams or tri-grams to capture word combinations and phrases that may carry sentiment, such as \"not good\" or \"very happy.\"\n",
        "\n",
        "TF-IDF (Term Frequency-Inverse Document Frequency) Features:\n",
        "TF-IDF Vector: Compute TF-IDF values for each word in the text. TF-IDF gives more weight to words that are unique to the document but not too common across all documents.\n",
        "Word Embeddings:\n",
        "\n",
        "Pre-trained Word Embeddings (e.g., Word2Vec, GloVe): Represent words as dense vectors in a continuous vector space. Average or concatenate word embeddings to form document-level embeddings.\n",
        "Sentiment Lexicons:\n",
        "\n",
        "Sentiment Lexicon Scores: Assign sentiment scores (e.g., positive, negative, or neutral) to words in the text based on a sentiment lexicon. Calculate overall sentiment score by aggregating word scores.\n",
        "\n",
        "Part-of-Speech (POS) Features:\n",
        "POS Tag Frequencies: Count the frequency of different POS tags (e.g., verbs, adjectives, adverbs) in the text. Analyze how the distribution of these tags correlates with sentiment.\n",
        "\n",
        "Emoticon and Emoji Analysis:\n",
        "Emoticon and Emoji Presence: Count the occurrence of emoticons and emojis in the text. Assign sentiment scores to commonly used emoticons and emojis.\n",
        "\n",
        "These features collectively provide a rich representation of text data, allowing a machine learning model to capture both explicit and nuanced sentiment expressions. Combining these features can enhance the accuracy and effectiveness of sentiment analysis models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOr1T1roiQgq"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97QekqGLiQgq",
        "outputId": "31c554f3-1ba5-4630-ddab-dcfe784ff8a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original DataFrame:\n",
            "                                                  Text\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n\n",
            "1                                 1having to do with\\n\n",
            "2    a POIGANT story about a young man who goes off...\n",
            "3                                 Synonyms for about\\n\n",
            "4                                                   \\n\n",
            "..                                                 ...\n",
            "117                                                 \\n\n",
            "118  asleep, dormant, dozing, napping, resting, sle...\n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...\n",
            "120                                      dreaming ME\\n\n",
            "121                             hypnotized, MESMERIZED\n",
            "\n",
            "[122 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to store the decoded data\n",
        "ashika_list = []\n",
        "\n",
        "# Local path to the data file\n",
        "file_path = \"D:\\\\Users\\\\Ashika\\\\Desktop\\\\Synonyms.txt\"\n",
        "\n",
        "# Open the file and read its content\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        # Remove newline characters and append the line to the list\n",
        "        decoded_data = line.replace('\\r\\n', '')\n",
        "        if decoded_data:\n",
        "            ashika_list.append(decoded_data)\n",
        "\n",
        "# Create a DataFrame using pandas with a column named 'Text'\n",
        "ashika_df = pd.DataFrame(ashika_list, columns=['Text'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(ashika_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jXBgNCUiQgt",
        "outputId": "22c658c2-b1b6-4b29-fd7d-09f6a3a588c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of Words' column:\n",
            "                                                  Text  Num of Words\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7\n",
            "1                                 1having to do with\\n             4\n",
            "2    a POIGANT story about a young man who goes off...            12\n",
            "3                                 Synonyms for about\\n             3\n",
            "4                                                   \\n             1\n",
            "..                                                 ...           ...\n",
            "117                                                 \\n             1\n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8\n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8\n",
            "120                                      dreaming ME\\n             2\n",
            "121                             hypnotized, MESMERIZED             2\n",
            "\n",
            "[122 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Function to find the number of words in a text\n",
        "def ashika_num_words(x):\n",
        "    return len(str(x).split(\" \"))\n",
        "\n",
        "# Apply the function to the 'Text' column and create a new column 'Num of Words'\n",
        "ashika_df['Num of Words'] = ashika_df['Text'].apply(lambda y: ashika_num_words(y))\n",
        "\n",
        "# Display the DataFrame after adding 'Num of Words' column\n",
        "print(\"\\nDataFrame after adding 'Num of Words' column:\")\n",
        "print(ashika_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIhvCbF6iQgt",
        "outputId": "59e39955-3258-4e62-f68e-580661d4624c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of Char' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  \n",
            "0             33  \n",
            "1             19  \n",
            "2             54  \n",
            "3             19  \n",
            "4              1  \n",
            "..           ...  \n",
            "117            1  \n",
            "118           76  \n",
            "119           62  \n",
            "120           12  \n",
            "121           22  \n",
            "\n",
            "[122 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Create a new column 'Num of Char' to store the number of characters in each text\n",
        "ashika_df['Num of Char'] = ashika_df['Text'].str.len()\n",
        "\n",
        "# Display the DataFrame after adding 'Num of Char' column\n",
        "print(\"\\nDataFrame after adding 'Num of Char' column:\")\n",
        "print(ashika_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tntl4z5UiQgu",
        "outputId": "d0dafca5-4aec-40a8-cdc9-2ac166053f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Avg Word Length' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  Avg Word Length  \n",
            "0             33         3.714286  \n",
            "1             19         3.750000  \n",
            "2             54         3.500000  \n",
            "3             19         5.333333  \n",
            "4              1              NaN  \n",
            "..           ...              ...  \n",
            "117            1              NaN  \n",
            "118           76         8.500000  \n",
            "119           62         6.750000  \n",
            "120           12         5.000000  \n",
            "121           22        10.500000  \n",
            "\n",
            "[122 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Function to find the average word length in a text\n",
        "def ashika_avg_word_length(x):\n",
        "    words = x.split()\n",
        "    if words:\n",
        "        return sum(len(word) for word in words) / len(words)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Apply the function to the 'Text' column and create a new column 'Avg Word Length'\n",
        "ashika_df['Avg Word Length'] = ashika_df['Text'].apply(lambda z: ashika_avg_word_length(z))\n",
        "\n",
        "# Display the DataFrame after adding 'Avg Word Length' column\n",
        "print(\"\\nDataFrame after adding 'Avg Word Length' column:\")\n",
        "print(ashika_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6Eqd1RciQgv",
        "outputId": "7d11193a-9403-4cae-9a8e-df07c79ce12e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of spec char' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  Avg Word Length  Num of spec char  \n",
            "0             33         3.714286                 9  \n",
            "1             19         3.750000                 4  \n",
            "2             54         3.500000                12  \n",
            "3             19         5.333333                 3  \n",
            "4              1              NaN                 1  \n",
            "..           ...              ...               ...  \n",
            "117            1              NaN                 1  \n",
            "118           76         8.500000                15  \n",
            "119           62         6.750000                15  \n",
            "120           12         5.000000                 2  \n",
            "121           22        10.500000                 2  \n",
            "\n",
            "[122 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# Function to find the number of special characters in a text\n",
        "def ashika_num_special_characters(x):\n",
        "    count = sum(not(char.isalpha()) and not(char.isdigit()) for char in x)\n",
        "    return count\n",
        "\n",
        "# Apply the function to the 'Text' column and create a new column 'Num of spec char'\n",
        "ashika_df['Num of spec char'] = ashika_df['Text'].apply(lambda y: ashika_num_special_characters(y))\n",
        "\n",
        "# Display the DataFrame after adding 'Num of spec char' column\n",
        "print(\"\\nDataFrame after adding 'Num of spec char' column:\")\n",
        "print(ashika_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sae1q3s0iQgv",
        "outputId": "4c6a5bb7-b44a-4a17-f2dc-a04b4b37b240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of num' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  Avg Word Length  Num of spec char  Num of num  \n",
            "0             33         3.714286                 9           1  \n",
            "1             19         3.750000                 4           0  \n",
            "2             54         3.500000                12           0  \n",
            "3             19         5.333333                 3           0  \n",
            "4              1              NaN                 1           0  \n",
            "..           ...              ...               ...         ...  \n",
            "117            1              NaN                 1           0  \n",
            "118           76         8.500000                15           0  \n",
            "119           62         6.750000                15           0  \n",
            "120           12         5.000000                 2           0  \n",
            "121           22        10.500000                 2           0  \n",
            "\n",
            "[122 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# Function to find the number of numerics in a text\n",
        "ashika_df['Num of num'] = ashika_df['Text'].apply(lambda x: len([word for word in x.split() if word.isdigit()]))\n",
        "\n",
        "# Display the DataFrame after adding 'Num of num' column\n",
        "print(\"\\nDataFrame after adding 'Num of num' column:\")\n",
        "print(ashika_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcLdOR-wiQgw",
        "outputId": "748493e2-3364-4d94-dcb7-a79c9ab2e0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DataFrame after adding 'Num of upper case words' column:\n",
            "                                                  Text  Num of Words  \\\n",
            "0                   Synonyms of about (Entry 1 of 3)\\n             7   \n",
            "1                                 1having to do with\\n             4   \n",
            "2    a POIGANT story about a young man who goes off...            12   \n",
            "3                                 Synonyms for about\\n             3   \n",
            "4                                                   \\n             1   \n",
            "..                                                 ...           ...   \n",
            "117                                                 \\n             1   \n",
            "118  asleep, dormant, dozing, napping, resting, sle...             8   \n",
            "119  dozy, drowsy, nodding, SLEEPY, slumberous (or ...             8   \n",
            "120                                      dreaming ME\\n             2   \n",
            "121                             hypnotized, MESMERIZED             2   \n",
            "\n",
            "     Num of Char  Avg Word Length  Num of spec char  Num of num  \\\n",
            "0             33         3.714286                 9           1   \n",
            "1             19         3.750000                 4           0   \n",
            "2             54         3.500000                12           0   \n",
            "3             19         5.333333                 3           0   \n",
            "4              1              NaN                 1           0   \n",
            "..           ...              ...               ...         ...   \n",
            "117            1              NaN                 1           0   \n",
            "118           76         8.500000                15           0   \n",
            "119           62         6.750000                15           0   \n",
            "120           12         5.000000                 2           0   \n",
            "121           22        10.500000                 2           0   \n",
            "\n",
            "     Num of upper case words  \n",
            "0                          0  \n",
            "1                          0  \n",
            "2                          1  \n",
            "3                          0  \n",
            "4                          0  \n",
            "..                       ...  \n",
            "117                        0  \n",
            "118                        0  \n",
            "119                        2  \n",
            "120                        1  \n",
            "121                        1  \n",
            "\n",
            "[122 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Function to find the number of uppercase words in a text\n",
        "ashika_df['Num of upper case words'] = ashika_df['Text'].apply(lambda x: len([word for word in x.split() if word.isupper()]))\n",
        "\n",
        "# Display the DataFrame after adding 'Num of upper case words' column:\n",
        "print(\"\\nDataFrame after adding 'Num of upper case words' column:\")\n",
        "print(ashika_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYUvXTtjiQgw"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF_HKhaJiQgx"
      },
      "source": [
        "Rank of most important features here:\n",
        "1. Number of sentences\n",
        "2. Number of Words\n",
        "3. Number of Characters\n",
        "4. Stowords\n",
        "5. Lowercase\n",
        "6. Removal of Punctuation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBZEfDBMiQgx"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTlmXvL1iQgx",
        "outputId": "d8533bb2-88af-4987-e9ab-39d778c993bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranked Documents based on Cosine Similarity for 'Ashika':\n",
            "Similarity: 0.9834\n",
            "Currently, Ashika is involved in a project focused on optimizing serverless architectures for better performance.\n",
            "\n",
            "Similarity: 0.9820\n",
            "Ashika is dedicated to creating scalable and efficient solutions for complex technical challenges.\n",
            "\n",
            "Similarity: 0.9804\n",
            "Outside of work, Ashika enjoys exploring new programming languages and building innovative projects.\n",
            "\n",
            "Similarity: 0.9517\n",
            "Ashika is a software engineer specializing in web development and cloud computing.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "\n",
        "# Different text data with the name 'ashika'\n",
        "ashika = [\n",
        "    \"Ashika is a software engineer specializing in web development and cloud computing.\",\n",
        "    \"Outside of work, Ashika enjoys exploring new programming languages and building innovative projects.\",\n",
        "    \"Ashika is dedicated to creating scalable and efficient solutions for complex technical challenges.\",\n",
        "    \"Currently, Ashika is involved in a project focused on optimizing serverless architectures for better performance.\"\n",
        "]\n",
        "\n",
        "# Your query with the name 'ashika'\n",
        "query_ashika = \"What technologies is Ashika currently exploring?\"\n",
        "\n",
        "# Load pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to get BERT embeddings for a given text\n",
        "def get_bert_embeddings_ashika(text):\n",
        "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "    embeddings = outputs.pooler_output.numpy()\n",
        "    return embeddings\n",
        "\n",
        "# Get BERT embeddings for the query and each document\n",
        "query_embedding_ashika = get_bert_embeddings_ashika(query_ashika)\n",
        "ashika_embeddings = [get_bert_embeddings_ashika(doc) for doc in ashika]\n",
        "\n",
        "# Calculate cosine similarity between the query and each document\n",
        "similarities_ashika = [cosine_similarity(query_embedding_ashika, doc_embedding)[0][0] for doc_embedding in ashika_embeddings]\n",
        "\n",
        "# Rank documents based on similarity in descending order\n",
        "ranked_ashika = sorted(zip(ashika, similarities_ashika), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Display the ranked documents with the name 'ashika'\n",
        "print(\"Ranked Documents based on Cosine Similarity for 'Ashika':\")\n",
        "for document, similarity in ranked_ashika:\n",
        "    print(f\"Similarity: {similarity:.4f}\\n{document}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Python 3.7.1)",
      "language": "python",
      "name": "py371"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}