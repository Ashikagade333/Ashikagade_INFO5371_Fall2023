{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashikagade333/Ashikagade_INFO5371_Fall2023/blob/main/In_class_exercise_04_03282023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FXU7QhFRHwq"
      },
      "source": [
        "# **The fourth in-class-exercise (40 points in total, 03/28/2022)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URzsJ3jxRHwt"
      },
      "source": [
        "Question description: Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdJVCdOsRHwu"
      },
      "source": [
        "## (1) (10 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import re\n",
        "import gensim\n",
        "import pyLDAvis.gensim_models\n",
        "from gensim.models import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import CoherenceModel\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "documents = ['Currently, Ashika is involved in a project focused on optimizing serverless architectures for better performance.',\n",
        "             'Ashika is dedicated to creating scalable and efficient solutions for complex technical challenges.',\n",
        "             'Outside of work, Ashika enjoys exploring new programming languages and building innovative projects.',\n",
        "             'Ashika is a software engineer specializing in web development and cloud computing.']\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess(text):\n",
        "    tokens = re.findall(r'\\w+', text.lower())\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "processed_documents = [preprocess(doc) for doc in documents]\n",
        "dictionary = Dictionary(processed_documents)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
        "coherence_scores = []\n",
        "for k in range(2, 11):\n",
        "    lda_model = LdaModel(corpus, num_topics=k, id2word=dictionary, passes=15)\n",
        "    coherence_model = CoherenceModel(model=lda_model, texts=processed_documents, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    coherence_scores.append(coherence_score)\n",
        "\n",
        "optimal_k = coherence_scores.index(max(coherence_scores)) + 2  # +2 because we started from K=2\n",
        "print(f\"The optimal number of topics is: {optimal_k}\")\n",
        "optimal_lda_model = LdaModel(corpus, num_topics=optimal_k, id2word=dictionary, passes=15)\n",
        "topics = optimal_lda_model.print_topics(num_words=10)  # Adjust the number of words as needed\n",
        "\n",
        "for topic in topics:\n",
        "    print(topic)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IfAx3PlTRYP",
        "outputId": "ad063755-bf56-4cf6-e907-2ca3c69ff9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The optimal number of topics is: 9\n",
            "(0, '0.029*\"ashika\" + 0.029*\"challenges\" + 0.029*\"web\" + 0.029*\"development\" + 0.029*\"computing\" + 0.029*\"creating\" + 0.029*\"architectures\" + 0.029*\"currently\" + 0.029*\"cloud\" + 0.029*\"solutions\"')\n",
            "(1, '0.029*\"ashika\" + 0.029*\"complex\" + 0.029*\"scalable\" + 0.029*\"specializing\" + 0.029*\"programming\" + 0.029*\"work\" + 0.029*\"building\" + 0.029*\"enjoys\" + 0.029*\"software\" + 0.029*\"development\"')\n",
            "(2, '0.080*\"serverless\" + 0.080*\"performance\" + 0.080*\"better\" + 0.080*\"currently\" + 0.080*\"focused\" + 0.080*\"involved\" + 0.080*\"optimizing\" + 0.080*\"architectures\" + 0.080*\"project\" + 0.080*\"ashika\"')\n",
            "(3, '0.086*\"ashika\" + 0.086*\"efficient\" + 0.086*\"solutions\" + 0.086*\"creating\" + 0.086*\"dedicated\" + 0.086*\"technical\" + 0.086*\"complex\" + 0.086*\"challenges\" + 0.086*\"scalable\" + 0.009*\"specializing\"')\n",
            "(4, '0.075*\"programming\" + 0.075*\"projects\" + 0.075*\"enjoys\" + 0.075*\"exploring\" + 0.075*\"innovative\" + 0.075*\"languages\" + 0.075*\"new\" + 0.075*\"outside\" + 0.075*\"building\" + 0.075*\"work\"')\n",
            "(5, '0.029*\"ashika\" + 0.029*\"project\" + 0.029*\"specializing\" + 0.029*\"software\" + 0.029*\"complex\" + 0.029*\"web\" + 0.029*\"cloud\" + 0.029*\"enjoys\" + 0.029*\"scalable\" + 0.029*\"languages\"')\n",
            "(6, '0.093*\"ashika\" + 0.093*\"web\" + 0.093*\"specializing\" + 0.093*\"software\" + 0.093*\"engineer\" + 0.093*\"development\" + 0.093*\"computing\" + 0.093*\"cloud\" + 0.009*\"scalable\" + 0.009*\"creating\"')\n",
            "(7, '0.029*\"ashika\" + 0.029*\"development\" + 0.029*\"scalable\" + 0.029*\"specializing\" + 0.029*\"web\" + 0.029*\"work\" + 0.029*\"exploring\" + 0.029*\"enjoys\" + 0.029*\"efficient\" + 0.029*\"computing\"')\n",
            "(8, '0.029*\"ashika\" + 0.029*\"complex\" + 0.029*\"specializing\" + 0.029*\"development\" + 0.029*\"web\" + 0.029*\"exploring\" + 0.029*\"computing\" + 0.029*\"building\" + 0.029*\"scalable\" + 0.029*\"software\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjFruNT7RHwy"
      },
      "source": [
        "## (2) (10 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqk_tscwRHwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77af7bac-ac93-43a2-8e7f-361de9bc488d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: technical, solutions, scalable, challenges, complex, creating, dedicated, efficient, cloud, engineer\n",
            "Topic 2: project, currently, involved, optimizing, performance, focused, serverless, architectures, better, computing\n",
            "Topic 3: work, projects, enjoys, exploring, languages, new, outside, programming, innovative, building\n",
            "Topic 4: development, specializing, software, web, cloud, computing, engineer, building, better, project\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "\n",
        "documents = ['Currently, Ashika is involved in a project focused on optimizing serverless architectures for better performance.',\n",
        "             'Ashika is dedicated to creating scalable and efficient solutions for complex technical challenges.',\n",
        "             'Outside of work, Ashika enjoys exploring new programming languages and building innovative projects.',\n",
        "             'Ashika is a software engineer specializing in web development and cloud computing.']\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.85, max_features=5000, stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "num_topics = 5\n",
        "lsa = TruncatedSVD(n_components=num_topics)\n",
        "lsa_topic_matrix = lsa.fit_transform(tfidf_matrix)\n",
        "terms = tfidf_vectorizer.get_feature_names_out()\n",
        "singular_values = lsa.singular_values_\n",
        "\n",
        "for i, singular_value in enumerate(singular_values):\n",
        "    top_terms = [terms[j] for j in np.argsort(lsa.components_[i])[::-1][:10]]\n",
        "    print(f\"Topic {i+1}: {', '.join(top_terms)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6nYH302RHwz"
      },
      "source": [
        "## (3) (10 points) Generate K topics by using  lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lda2vec pyLDAvis gensim\n"
      ],
      "metadata": {
        "id": "Iwl_uH52i9my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6lsxEIokDBo",
        "outputId": "d2880edb-b45b-40c1-f68b-3f69b2012990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.corpora import Dictionary\n",
        "nltk.download('punkt')\n",
        "documents = ['Currently, Ashika is involved in a project focused on optimizing serverless architectures for better performance.',\n",
        "             'Ashika is dedicated to creating scalable and efficient solutions for complex technical challenges.',\n",
        "             'Outside of work, Ashika enjoys exploring new programming languages and building innovative projects.',\n",
        "             'Ashika is a software engineer specializing in web development and cloud computing.']\n",
        "\n",
        "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
        "\n",
        "dictionary = Dictionary(tokenized_docs)\n",
        "\n",
        "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "def compute_coherence_values(dictionary, corpus, tokenized_docs, limit, start=2, step=1):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        model_list.append(model)\n",
        "        coherence_model = CoherenceModel(model=model, texts=tokenized_docs, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherence_model.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values\n",
        "\n",
        "model_list, coherence_values = compute_coherence_values(dictionary, corpus, tokenized_docs, limit=10)\n",
        "\n",
        "optimal_model = model_list[coherence_values.index(max(coherence_values))]\n",
        "optimal_K = optimal_model.num_topics\n",
        "def summarize_topics(model):\n",
        "    topics = model.print_topics(num_words=5)\n",
        "    for topic in topics:\n",
        "        print(topic)\n",
        "\n",
        "summarize_topics(optimal_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "qDy-43YE3YeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2985f47-ef0e-4bdb-84ad-2d2d106ef89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.058*\"ashika\" + 0.058*\"a\" + 0.056*\"in\" + 0.056*\"is\" + 0.056*\".\"')\n",
            "(1, '0.048*\"better\" + 0.047*\"in\" + 0.047*\".\" + 0.045*\"optimizing\" + 0.045*\"project\"')\n",
            "(2, '0.052*\"ashika\" + 0.052*\"and\" + 0.052*\",\" + 0.052*\".\" + 0.052*\"enjoys\"')\n",
            "(3, '0.040*\"is\" + 0.040*\"a\" + 0.039*\"currently\" + 0.037*\",\" + 0.037*\"involved\"')\n",
            "(4, '0.022*\".\" + 0.022*\"and\" + 0.022*\"ashika\" + 0.022*\"is\" + 0.022*\"for\"')\n",
            "(5, '0.054*\".\" + 0.054*\"to\" + 0.054*\"is\" + 0.054*\"for\" + 0.054*\"challenges\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8x8u4MeRHw0"
      },
      "source": [
        "## (4) (10 points) Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd7vtjaARHw1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "86897d50016943c994a85ccadf14bdcf",
            "41ceecfa9eb74835ad3c7c1d35ee0b7a",
            "97c9a730a83b4551b44309b43635b706",
            "1e9d1f7812844e3f8566667979c6d2c2",
            "14a0e36a9fcc49159ba297729eb81481",
            "fb0f577359da417caedce9696466158b",
            "4e12ad8633244589ae541b41bcb62998",
            "0e5cc7b143f44c73acff1008a3132142",
            "7f5d7e35fa6f4370a391a3bdc47bc8fd",
            "c7d0fb027a4c440689f486ab1c139fd3",
            "43f38e29614446debee73a659640666e"
          ]
        },
        "outputId": "5e1ea307-3f05-43bc-b31a-e7c7c1a093ff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86897d50016943c994a85ccadf14bdcf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/589 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-04 22:01:17,159 - BERTopic - Transformed documents to Embeddings\n",
            "2023-11-04 22:01:45,550 - BERTopic - Reduced dimensionality\n",
            "2023-11-04 22:03:12,669 - BERTopic - Clustered reduced embeddings\n",
            "2023-11-04 22:03:27,250 - BERTopic - Reduced number of topics from 336 to 149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic -1: the, to, of, and, in (Freq: 5666)\n",
            "Topic 1: game, team, he, games, players (Freq: 1560)\n",
            "Topic 2: cancer, disease, patients, pain, lyme (Freq: 205)\n",
            "Topic 3: x11r5, error, xdm, symbol, sunos (Freq: 137)\n",
            "Topic 4: msg, food, sensitivity, chinese, foods (Freq: 128)\n",
            "Topic 5: moon, lunar, billion, space, prize (Freq: 112)\n",
            "Topic 6: sky, space, vandalizing, billboard, advertising (Freq: 95)\n",
            "Topic 7: sale, ticket, hotel, airline, summer (Freq: 74)\n",
            "Topic 8: insurance, health, private, care, canadian (Freq: 70)\n",
            "Topic 9: copy, protected, protection, disks, program (Freq: 60)\n",
            "Topic 10: mary, her, she, sin, immaculate (Freq: 59)\n",
            "Topic 11: window, manager, dialog, event, events (Freq: 59)\n",
            "Topic 12: shift, shifting, manual, automatic, clutch (Freq: 53)\n",
            "Topic 13: gamma, bursters, oort, ray, cloud (Freq: 51)\n",
            "Topic 14: battery, batteries, concrete, acid, lead (Freq: 51)\n",
            "Topic 15: dog, dogs, springer, bike, my (Freq: 50)\n",
            "Topic 16: candida, yeast, infections, systemic, patients (Freq: 50)\n",
            "Topic 17: fonts, font, truetype, atm, tt (Freq: 49)\n",
            "Topic 18: sound, midi, stereo, channel, driver (Freq: 48)\n",
            "Topic 19: hst, mission, servicing, shuttle, reboost (Freq: 47)\n",
            "Topic 20: oil, drain, changing, plug, self (Freq: 46)\n",
            "Topic 21: jewish, baseball, players, lowenstein, koufax (Freq: 44)\n",
            "Topic 22: cpu, fan, heat, fans, sink (Freq: 42)\n",
            "Topic 23: countersteering, bike, countersteeringfaq, lean, left (Freq: 42)\n",
            "Topic 24: celp, speech, compression, voice, gtoalgtoalcom (Freq: 41)\n",
            "Topic 25: helmet, helmets, shoei, jacket, fit (Freq: 39)\n",
            "Topic 26: marriage, married, marry, church, ceremony (Freq: 39)\n",
            "Topic 27: drugs, drug, illegal, cocaine, marijuana (Freq: 38)\n",
            "Topic 28: centaur, proton, energy, uranium, protoncentaur (Freq: 38)\n",
            "Topic 29: photography, krillean, kirlian, pictures, leaf (Freq: 38)\n",
            "Topic 30: monitors, hours, 24, day, power (Freq: 38)\n",
            "Topic 31: kuwait, saudi, iraq, arabia, war (Freq: 38)\n",
            "Topic 32: polygon, polygons, routine, convex, fast (Freq: 37)\n",
            "Topic 33: baptism, sin, aaron, original, infants (Freq: 37)\n",
            "Topic 34: shots, skin, allergy, nose, rutin (Freq: 36)\n",
            "Topic 35: newsgroup, split, group, ch, groups (Freq: 35)\n",
            "Topic 36: ham, audio, relays, radio, power (Freq: 33)\n",
            "Topic 37: wave, bikers, squids, waving, cage (Freq: 33)\n",
            "Topic 38: points, sphere, den, radius, circle (Freq: 32)\n",
            "Topic 39: tempest, monitor, holland, emissions, electromagnetic (Freq: 31)\n",
            "Topic 40: phone, line, number, tip, ring (Freq: 31)\n",
            "Topic 41: 1st, wolverine, comics, hulk, art (Freq: 28)\n",
            "Topic 42: keyboard, accelerators, numlock, keys, emacs (Freq: 27)\n",
            "Topic 43: wax, scratches, plastic, paint, finish (Freq: 26)\n",
            "Topic 44: duo, 230, beeps, machine, chimes (Freq: 26)\n",
            "Topic 45: satan, ra, god, bible, heaven (Freq: 26)\n",
            "Topic 46: odometer, bmw, sensor, car, mileage (Freq: 26)\n",
            "Topic 47: april, spacecraft, pluto, galileo, mission (Freq: 25)\n",
            "Topic 48: 130, speed, 80, roads, fast (Freq: 25)\n",
            "Topic 49: ir, detector, cycle, detection, pin (Freq: 24)\n",
            "Topic 50: irq, interrupt, port, soundblaster, parallel (Freq: 24)\n",
            "Topic 51: stove, electric, napalm, dividian, wood (Freq: 24)\n",
            "Topic 52: r12, air, substitutes, conditioning, heat (Freq: 24)\n",
            "Topic 53: engine, mr2, clutch, mr2s, noisy (Freq: 24)\n",
            "Topic 54: scope, scopes, oscilloscope, dtmedincatbyteb30ingrcom, phosphor (Freq: 23)\n",
            "Topic 55: motif, linux, bindings, athena, software (Freq: 23)\n",
            "Topic 56: ftp, pctcp, nonibm, wuarchive, brpctrlgstanfordedu (Freq: 23)\n",
            "Topic 57: solvent, adhesive, ducttape, mek, acetone (Freq: 23)\n",
            "Topic 58: pillion, riding, advice, passenger, ride (Freq: 23)\n",
            "Topic 59: chromium, weight, fat, diet, wa7kgx (Freq: 22)\n",
            "Topic 60: maxaxaxaxaxaxaxaxaxaxaxaxaxaxax, mg9vg9vg9vg9vg9vg9vg9vg9vg9vg9vg9vg9vg9vg9vg9v, pwisemansalmonusdedu, cliff, answerfax (Freq: 22)\n",
            "Topic 61: abortion, abortions, choice, pay, health (Freq: 22)\n",
            "Topic 62: mouse, driver, windows, com3, com1 (Freq: 22)\n",
            "Topic 63: uva, jefferson, partying, andi, beyer (Freq: 21)\n",
            "Topic 64: punishment, penalty, death, murder, capital (Freq: 21)\n",
            "Topic 65: crohns, inflammation, ibd, disease, diet (Freq: 21)\n",
            "Topic 66: lens, camera, nikon, goldbergoasysdtnavymil, zoom (Freq: 21)\n",
            "Topic 67: dialing, phones, tone, sweden, phone (Freq: 20)\n",
            "Topic 68: sabbath, law, worship, jesus, paul (Freq: 20)\n",
            "Topic 69: chemistry, 02106chopinudeledu, book, neural, paperback (Freq: 20)\n",
            "Topic 70: leds, blue, boards, green, solder (Freq: 20)\n",
            "Topic 71: eye, dominance, prk, rk, righteye (Freq: 20)\n",
            "Topic 72: gas, tear, cs, riddle, children (Freq: 20)\n",
            "Topic 73: mouse, motion, jumpy, smoothly, jump (Freq: 19)\n",
            "Topic 74: kidney, stones, she, calcium, b6 (Freq: 19)\n",
            "Topic 75: joystick, joysticks, arcade, port, int15h (Freq: 19)\n",
            "Topic 76: comet, jupiter, gehrels, orbit, temporary (Freq: 19)\n",
            "Topic 77: cancer, medical, circumcision, centers, center (Freq: 19)\n",
            "Topic 78: geico, insurance, claim, companies, wonnacott (Freq: 19)\n",
            "Topic 79: rosicrucian, amorc, orders, ch981clevelandfreenetedu, oto (Freq: 18)\n",
            "Topic 80: 42, tiff, philosophical, significance, joachimkihno (Freq: 18)\n",
            "Topic 81: mithras, oto, order, reuss, cybele (Freq: 18)\n",
            "Topic 82: pregnency, biology, teacher, sperm, sex (Freq: 18)\n",
            "Topic 83: icon, icons, program, manager, change (Freq: 18)\n",
            "Topic 84: chain, wax, maxima, spooge, cookson (Freq: 17)\n",
            "Topic 85: orion, film, prototype, vacuum, leigh (Freq: 17)\n",
            "Topic 86: duo, dock, apple, duodock, processor (Freq: 17)\n",
            "Topic 87: water, phd, dept, meteorologist, atmospheric (Freq: 17)\n",
            "Topic 88: janet, reno, children, madman, she (Freq: 17)\n",
            "Topic 89: wire, wiring, ground, neutral, outlets (Freq: 17)\n",
            "Topic 90: prophecy, prophecies, lord, earthquake, prophesies (Freq: 17)\n",
            "Topic 91: ear, earwax, ears, dizziness, aids (Freq: 17)\n",
            "Topic 92: xv, escaped, copyright, shareware, donation (Freq: 17)\n",
            "Topic 93: tires, tire, fluids, brake, braking (Freq: 17)\n",
            "Topic 94: cooling, towers, nuclear, water, plants (Freq: 17)\n",
            "Topic 95: gc, mydisplay, draw, gxxor, visual (Freq: 17)\n",
            "Topic 96: uv, bulb, flashlight, bulbs, neon (Freq: 17)\n",
            "Topic 97: logo, startup, wincom, windows, rle (Freq: 16)\n",
            "Topic 98: diesels, diesel, fuel, emissions, injector (Freq: 16)\n",
            "Topic 99: alarm, sensor, car, alarms, acceleration (Freq: 16)\n",
            "Topic 100: wheelies, chain, shaft, shaftdrives, efficient (Freq: 16)\n",
            "Topic 101: pat, accessdigexnet, express, online, communications (Freq: 16)\n",
            "Topic 102: updating, winini, ini, svein, utility (Freq: 15)\n",
            "Topic 103: gauge, gauges, cigarette, feagans, ashtrays (Freq: 15)\n",
            "Topic 104: quadra, scsi, cartridge, mac, problems (Freq: 15)\n",
            "Topic 105: wrench, srb, thiokol, tool, pliers (Freq: 14)\n",
            "Topic 106: cruel, keith, constitution, painful, iroquois (Freq: 14)\n",
            "Topic 107: drinking, riding, drink, drinks, alcohol (Freq: 14)\n",
            "Topic 108: lock, locks, cobra, kryptonite, cable (Freq: 14)\n",
            "Topic 109: hacker, ethic, hackers, computer, where (Freq: 14)\n",
            "Topic 110: octopus, ice, detroit, tradition, zazula (Freq: 14)\n",
            "Topic 111: selective, service, c17, abolish, pork (Freq: 14)\n",
            "Topic 112: carbs, exhaust, intake, air, engine (Freq: 14)\n",
            "Topic 113: easter, resurrection, celebration, pagan, goddess (Freq: 13)\n",
            "Topic 114: movies, bikes, csundh30ursacalvinedu, sundheim, assembling (Freq: 13)\n",
            "Topic 115: lights, dumbest, stalk, automotive, backing (Freq: 13)\n",
            "Topic 116: fax, modem, supra, teleport, gateway (Freq: 13)\n",
            "Topic 117: software, level, process, wingert, bret (Freq: 13)\n",
            "Topic 118: vhs, kou, movie, 1100, movies (Freq: 13)\n",
            "Topic 119: temperature, sky, interstellar, radiation, dust (Freq: 13)\n",
            "Topic 120: nubus, pds, lc, iii, slot (Freq: 13)\n",
            "Topic 121: windy, wind, whenhow, yukyukyuk, ride (Freq: 13)\n",
            "Topic 122: car, safety, saftey, accident, important (Freq: 13)\n",
            "Topic 123: tongues, language, tounges, gifted, languages (Freq: 13)\n",
            "Topic 124: varma, seema, ad, converter, test (Freq: 13)\n",
            "Topic 125: cview, temp, files, directory, zenkar (Freq: 13)\n",
            "Topic 126: pope, schism, church, catholic, sspx (Freq: 13)\n",
            "Topic 127: tape, copy, vcr, tapes, selfdestructing (Freq: 13)\n",
            "Topic 128: vmax, handling, ba7116326ntuvaxntuacsg, handson, pls (Freq: 12)\n",
            "Topic 129: tank, tankbag, zipper, fj11001200, blaine (Freq: 12)\n",
            "Topic 130: autotrace, illustrator, points, drawing, errors (Freq: 12)\n",
            "Topic 131: sunset, sunrise, times, wetstein, jpwcbisecedrexeledu (Freq: 12)\n",
            "Topic 132: font, dos, windows, fonts, alavi (Freq: 12)\n",
            "Topic 133: moment, silence, prayer, opposing, pray (Freq: 12)\n",
            "Topic 134: xputimage, sunview, server, animation, dcrmailastcamacuk (Freq: 12)\n",
            "Topic 135: mattingly, don, drm6640teslanjitedu, baseman, best (Freq: 11)\n",
            "Topic 136: dock, inflatable, envelope, space, boom (Freq: 11)\n",
            "Topic 137: cnn, siggraph, sale, 100000, membership (Freq: 11)\n",
            "Topic 138: date, clock, dos, bios, menu (Freq: 11)\n",
            "Topic 139: de, het, van, een, vulcan (Freq: 11)\n",
            "Topic 140: habitable, planets, atmosphere, oxygen, planet (Freq: 11)\n",
            "Topic 141: needles, acupuncture, needle, aids, hypodermic (Freq: 11)\n",
            "Topic 142: moscow, kaliningrad, aviation, russian, tsniimach (Freq: 11)\n",
            "Topic 143: code, pgp, distributable, freely, public (Freq: 11)\n",
            "Topic 144: widget, appcontext, menubutton, bitmap, athena (Freq: 11)\n",
            "Topic 145: aid, russia, julie, conservatives, libertarian (Freq: 10)\n",
            "Topic 146: solar, sail, sails, projects, snydefjengauburnedu (Freq: 10)\n",
            "Topic 147: widgets, gadgets, widget, motif, dealy (Freq: 10)\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "from bertopic import BERTopic\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "data = fetch_20newsgroups(subset='all')['data']\n",
        "\n",
        "topic_model = BERTopic(nr_topics=\"auto\", calculate_probabilities=True, verbose=True)\n",
        "topics, _ = topic_model.fit_transform(data)\n",
        "\n",
        "topic_overview = topic_model.get_topic_freq()\n",
        "\n",
        "for topic_num, freq in topic_overview[1:].values:\n",
        "    topic_words = topic_model.get_topic(topic_num)\n",
        "    topic_summary = \", \".join([word[0] for word in topic_words[:5]])\n",
        "    print(f\"Topic {topic_num}: {topic_summary} (Freq: {freq})\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lr4GRsFRHw2"
      },
      "source": [
        "## (5) (10 extra points) Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtUqtCxIRHw2"
      },
      "outputs": [],
      "source": [
        "# Write your answer here (no code needed for this question)\n",
        "\n",
        "-LSA seems to be the most straightforward with clear topics but may lack depth in capturing more nuanced relationships.\n",
        "\n",
        "-LDA provided coherent topics related to the text and is widely adopted due to its probabilistic nature and interpretability.\n",
        "\n",
        "-lda2vec might be more powerful when nuances in the text are critical, but it requires more fine-tuning to get interpretable topics.\n",
        "\n",
        "-BERTopic showed a broad range of topics and is excellent for diverse and large text corpuses.\n",
        " However, it requires more computational resources and may sometimes need post-processing for best results.\n",
        "\n",
        "-For general interpretability and a balance between complexity and performance, LDA might be the best choice.\n",
        "-If computational resources are available and the corpus is diverse, BERTopic can be highly effective.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "86897d50016943c994a85ccadf14bdcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41ceecfa9eb74835ad3c7c1d35ee0b7a",
              "IPY_MODEL_97c9a730a83b4551b44309b43635b706",
              "IPY_MODEL_1e9d1f7812844e3f8566667979c6d2c2"
            ],
            "layout": "IPY_MODEL_14a0e36a9fcc49159ba297729eb81481"
          }
        },
        "41ceecfa9eb74835ad3c7c1d35ee0b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb0f577359da417caedce9696466158b",
            "placeholder": "​",
            "style": "IPY_MODEL_4e12ad8633244589ae541b41bcb62998",
            "value": "Batches: 100%"
          }
        },
        "97c9a730a83b4551b44309b43635b706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5cc7b143f44c73acff1008a3132142",
            "max": 589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f5d7e35fa6f4370a391a3bdc47bc8fd",
            "value": 589
          }
        },
        "1e9d1f7812844e3f8566667979c6d2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d0fb027a4c440689f486ab1c139fd3",
            "placeholder": "​",
            "style": "IPY_MODEL_43f38e29614446debee73a659640666e",
            "value": " 589/589 [37:08&lt;00:00,  1.36it/s]"
          }
        },
        "14a0e36a9fcc49159ba297729eb81481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0f577359da417caedce9696466158b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e12ad8633244589ae541b41bcb62998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e5cc7b143f44c73acff1008a3132142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5d7e35fa6f4370a391a3bdc47bc8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d0fb027a4c440689f486ab1c139fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43f38e29614446debee73a659640666e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}